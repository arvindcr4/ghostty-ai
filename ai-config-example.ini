# Ghostty AI Configuration Example
# This file shows how to configure Ghostty's AI features similar to Warp terminal

# Enable AI assistant features
ai-enabled = true

# AI Provider Configuration
# Choose one: openai, anthropic, ollama, custom
ai-provider = openai

# API Key (required for cloud providers)
# Use environment variable for security
ai-api-key = ${OPENAI_API_KEY}
# For Anthropic: ai-api-key = ${ANTHROPIC_API_KEY}
# For Ollama: no API key needed for local instance

# Model Selection
# OpenAI models: gpt-4-turbo, gpt-4, gpt-3.5-turbo
# Anthropic models: claude-3-opus, claude-3-sonnet, claude-3-haiku
# Ollama models: llama2, codellama, mistral, etc.
ai-model = gpt-4-turbo

# Response Configuration
ai-max-tokens = 1000
ai-temperature = 0.7

# Context Awareness
ai-context-aware = true
ai-context-lines = 50

# Keybinding to trigger AI input mode
# You can use any key combination
keybind = ctrl+space=ai_input_mode
# Alternative bindings:
# keybind = cmd+space=ai_input_mode  # macOS
# keybind = alt+space=ai_input_mode  # Alternative

# Example with Anthropic Claude
# ai-provider = anthropic
# ai-api-key = ${ANTHROPIC_API_KEY}
# ai-model = claude-3-opus-20240229

# Example with Local Ollama
# ai-provider = ollama
# ai-endpoint = http://localhost:11434
# ai-model = codellama

# Example with Custom OpenAI-compatible Endpoint
# ai-provider = custom
# ai-endpoint = https://your-api-endpoint.com/v1
# ai-api-key = ${CUSTOM_API_KEY}
# ai-model = gpt-3.5-turbo